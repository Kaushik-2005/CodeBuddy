# ğŸ§ª CodeBuddy Test Suite

This directory contains comprehensive tests and debugging utilities for the CodeBuddy project.

## ğŸ“ Test File Organization

### ğŸ”¬ **Unit Tests**
- `test_analysis_tools.py` - Code analysis functionality tests
- `test_git_tools.py` - Git operations and workflow tests
- `test_safety_system.py` - Safety approval system tests
- `test_new_features.py` - Feature integration tests

### ğŸ”§ **Integration Tests**
- `test_safety_integration.py` - Safety system integration with tools
- `test_real_gemini.py` - Real Gemini API integration tests

### ğŸ› **Debug Utilities**
- `debug_agent.py` - Agent core debugging
- `debug_gemini_direct.py` - Direct Gemini API testing
- `debug_git_risk.py` - Git risk assessment debugging
- `debug_llm.py` - LLM client debugging
- `debug_params.py` - Parameter parsing debugging
- `debug_real_llm.py` - Real LLM response debugging

### ğŸ“ **Sample Files**
- `test_analysis_file.py` - Sample file with various code issues for analysis testing
- `calculator.py` - Simple calculator for execution tests
- `hello_world.py` - Basic Python file for testing
- `simple_test.py` - Minimal test file

### ğŸ“‚ **Test Directories**
- `my_tests/` - Sample test directory
- `test_folder/` - Another test directory
- `test_real_gemini/` - Real Gemini test artifacts

## ğŸš€ Running Tests

### Quick Test Commands
```bash
# Run all analysis tool tests
python tests/test_analysis_tools.py

# Test Git functionality
python tests/test_git_tools.py

# Test safety system
python tests/test_safety_system.py

# Test with real Gemini API
python tests/test_real_gemini.py
```

### Debug Mode Testing
```bash
# Debug agent core
python tests/debug_agent.py

# Debug LLM responses
python tests/debug_real_llm.py

# Debug parameter parsing
python tests/debug_params.py
```

## ğŸ“Š Test Coverage

### File Operations
- âœ… File reading and writing
- âœ… Directory creation and deletion
- âœ… File content generation
- âœ… Error handling for missing files

### Code Execution
- âœ… Python file execution
- âœ… Shell command execution
- âœ… Syntax validation
- âœ… Output capture and error handling

### Git Operations
- âœ… Repository status checking
- âœ… File staging and commits
- âœ… Branch management
- âœ… Remote operations
- âœ… Diff and log viewing

### Analysis Tools
- âœ… Python linting with various issue types
- âœ… Complexity analysis with metrics
- âœ… Security scanning with vulnerability detection
- âœ… Dependency analysis
- âœ… Comprehensive quality assessment

### Safety System
- âœ… Risk assessment for all operation types
- âœ… Approval workflow testing
- âœ… User interaction simulation
- âœ… Safety rule validation

## ğŸ” Test Examples

### Analysis Tool Testing
```python
# test_analysis_tools.py demonstrates:
def test_analysis_tools():
    """Test analysis tools with the agent"""
    agent = create_agent(debug=True)
    
    test_requests = [
        "lint main.py",
        "analyze complexity main.py", 
        "security scan main.py",
        "analyze dependencies",
        "code quality main.py",
    ]
    
    for request in test_requests:
        result = agent.process_request(request)
        print(f"Result: {result}")
```

### Safety System Testing
```python
# test_safety_system.py demonstrates:
def test_risk_assessment():
    """Test risk assessment for various operations"""
    safety = SafetyApprovalSystem()
    
    test_cases = [
        ("delete_file", {"filepath": "main.py"}, "High risk file"),
        ("git_push", {"remote": "origin", "branch": "main"}, "Push to main"),
        ("run_command", {"command": "rm -rf /"}, "Critical command"),
    ]
    
    for operation, params, description in test_cases:
        risk = safety.assess_risk(operation, **params)
        print(f"Operation: {operation}, Risk: {risk.value}")
```

## ğŸ¯ Test Scenarios

### Positive Test Cases
- âœ… Valid file operations with proper parameters
- âœ… Successful Git workflows
- âœ… Clean code analysis results
- âœ… Approved safety operations

### Negative Test Cases
- âœ… Invalid file paths and missing files
- âœ… Malformed Git commands
- âœ… Code with multiple issues and vulnerabilities
- âœ… Rejected safety operations

### Edge Cases
- âœ… Empty files and directories
- âœ… Very large files
- âœ… Complex Git repository states
- âœ… Boundary conditions for risk assessment

## ğŸ”§ Test Utilities

### Mock LLM Testing
The test suite includes comprehensive mock LLM responses for offline testing:
```python
# Mock responses cover all tool types
mock_responses = {
    "lint main.py": "python_lint(filepath='main.py')",
    "git status": "git_status()",
    "security scan file.py": "security_scan(filepath='file.py')",
}
```

### Test Data Generation
Several utilities create test data for analysis:
```python
def create_test_file():
    """Create a test file with various issues for analysis"""
    test_code = '''
    # File with intentional issues for testing
    import os
    API_KEY = "hardcoded-secret"  # Security issue
    
    def long_function(a, b, c, d, e, f, g):  # Too many params
        os.system("rm " + a)  # Command injection
        eval(b)  # Code injection
    '''
```

## ğŸ“ˆ Performance Testing

### Execution Time Benchmarks
- **File Operations**: < 100ms average
- **Git Operations**: 200-500ms average  
- **Analysis Tools**: 500ms-2s depending on file size
- **Safety Assessments**: < 50ms average

### Memory Usage Testing
- **Base Agent**: ~50MB
- **With All Tools**: ~80MB
- **Analysis Cache**: ~20MB additional

## ğŸ› Debugging Guide

### Common Issues and Solutions

#### LLM Response Parsing
```bash
# Debug LLM responses
python tests/debug_real_llm.py

# Check parameter parsing
python tests/debug_params.py
```

#### Git Operations
```bash
# Debug Git risk assessment
python tests/debug_git_risk.py

# Test Git tools directly
python tests/test_git_tools.py
```

#### Safety System
```bash
# Test safety approval flows
python tests/test_safety_system.py

# Debug safety integration
python tests/test_safety_integration.py
```

## ğŸ“ Test Maintenance

### Adding New Tests
1. Create test file in appropriate category
2. Follow naming convention: `test_*.py` or `debug_*.py`
3. Include both positive and negative test cases
4. Add documentation and examples
5. Update this README with new test descriptions

### Test File Template
```python
#!/usr/bin/env python3
"""Test description and purpose"""

from main import create_agent

def test_feature():
    """Test specific feature functionality"""
    agent = create_agent(debug=True)
    
    # Test implementation
    result = agent.process_request("test command")
    assert "expected" in result
    
    print("âœ… Test passed")

if __name__ == "__main__":
    test_feature()
```

## ğŸ¯ Future Test Enhancements

### Planned Additions
- **Automated Test Runner**: Pytest integration
- **Performance Benchmarks**: Automated performance testing
- **Integration Tests**: End-to-end workflow testing
- **Stress Tests**: High-load and edge case testing
- **Mock API Tests**: Complete offline testing capability

### Test Metrics Goals
- **Code Coverage**: > 90%
- **Test Execution Time**: < 30 seconds for full suite
- **Test Reliability**: > 99% pass rate
- **Documentation Coverage**: 100% of test files documented

---

**Happy Testing! ğŸ§ª**

*Comprehensive testing ensures CodeBuddy remains reliable, safe, and powerful.*
